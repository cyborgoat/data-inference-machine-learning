{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARNEGIE MELLON UNIVERSITY\n",
    "\n",
    "**Name**: Junxiao Guo\n",
    "\n",
    "**Andrew ID**: junxiaog\n",
    "\n",
    "**Course**: DATA, INFERENCE & APPLIED MACHINE LEARNING (COURSE 18-785)\n",
    "\n",
    "**ASSIGNMENT 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/robert/anaconda3/lib/python3.7/site-packages (1.17.3)\n",
      "Requirement already satisfied: pandas in /Users/robert/anaconda3/lib/python3.7/site-packages (0.25.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/robert/anaconda3/lib/python3.7/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/robert/anaconda3/lib/python3.7/site-packages (from pandas) (1.17.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/robert/anaconda3/lib/python3.7/site-packages (from pandas) (2019.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/robert/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Requirement already satisfied: matplotlib in /Users/robert/anaconda3/lib/python3.7/site-packages (3.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/robert/anaconda3/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/robert/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/robert/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/robert/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /Users/robert/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.17.3)\n",
      "Requirement already satisfied: six in /Users/robert/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /Users/robert/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n",
      "Requirement already satisfied: scipy in /Users/robert/anaconda3/lib/python3.7/site-packages (1.3.1)\n",
      "Requirement already satisfied: sklearn in /Users/robert/anaconda3/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/robert/anaconda3/lib/python3.7/site-packages (from sklearn) (0.21.3)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Users/robert/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/robert/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /Users/robert/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.17.3)\n",
      "Requirement already satisfied: seaborn in /Users/robert/anaconda3/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /Users/robert/anaconda3/lib/python3.7/site-packages (from seaborn) (1.3.1)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /Users/robert/anaconda3/lib/python3.7/site-packages (from seaborn) (0.25.2)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /Users/robert/anaconda3/lib/python3.7/site-packages (from seaborn) (3.1.1)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /Users/robert/anaconda3/lib/python3.7/site-packages (from seaborn) (1.17.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/robert/anaconda3/lib/python3.7/site-packages (from pandas>=0.15.2->seaborn) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/robert/anaconda3/lib/python3.7/site-packages (from pandas>=0.15.2->seaborn) (2019.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/robert/anaconda3/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/robert/anaconda3/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/robert/anaconda3/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (2.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/robert/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas>=0.15.2->seaborn) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /Users/robert/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (41.2.0)\n",
      "Requirement already satisfied: RegscorePy in /Users/robert/anaconda3/lib/python3.7/site-packages (1.1)\n",
      "Requirement already satisfied: numpy in /Users/robert/anaconda3/lib/python3.7/site-packages (from RegscorePy) (1.17.3)\n",
      "Requirement already satisfied: pandas in /Users/robert/anaconda3/lib/python3.7/site-packages (from RegscorePy) (0.25.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/robert/anaconda3/lib/python3.7/site-packages (from pandas->RegscorePy) (2019.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/robert/anaconda3/lib/python3.7/site-packages (from pandas->RegscorePy) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/robert/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas->RegscorePy) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "# %config IPCompleter.greedy=True\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !pip install scipy\n",
    "# !pip install sklearn\n",
    "# !pip install seaborn\n",
    "# !pip install RegscorePy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINIHSED PROBLEMS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Statistical learning (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Describe at least four steps to implementing a rule-based approach to decision-making and give an example. Is any domain knowledge required to establish a rule? Support your answer with an explanation.\n",
    "\n",
    "#### **Steps**:\n",
    "\n",
    "\n",
    "- A list of rules or rule base, which is a specific type of knowledge base.\n",
    "- An inference engine or semantic reasoner, which infers information or takes action based on the interaction of input and the rule base. The interpreter executes a production system program by performing the following match-resolve-act cycle.\n",
    "- Temporary working memory.\n",
    "- A user interface or other connection to the outside world through which input and output signals are received and sent.\n",
    "\n",
    "#### **Example**: \n",
    "\n",
    "1.2 Explain over-fitting and why it is a problem in statistical learning. If you have a small dataset containing ten data points, should you prefer a simple model with one parameter or a complex model with ten parameters? Support your answer with an explanation.\n",
    "\n",
    "**Overfitting**: In statistics, overfitting is \"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably\". An overfitted model is a statistical model that contains more parameters than can be justified by the data.The essence of overfitting is to have unknowingly extracted some of the residual variation (i.e. the noise) as if that variation represented underlying model structure.\n",
    "\n",
    "**For small dataset**: If we only have a small dataset of ten data points, we **should use s simple model** because if we use a complex model, it will be ealisy get overfitted because complex model can easily be trained to fit every datapoints from the small dataset, which will lose the generality of our model.\n",
    "\n",
    "\n",
    "\n",
    "1.3 There are two commonly used approaches to avoid over-fitting; describe each one.\n",
    "\n",
    "- **Simplifying the model**: make sure that the number of independent parameters in your fit is much smaller than the number of data points you have.  By independent parameters, I mean the number of coefficients in a polynomial or the number of weights and biases in a neural network, not the number of independent variables\n",
    "\n",
    "- **Adding Regulirazations**: Regularization attemts to reduce the variance of the estimator by simplifying it, something that will increase the bias, in such a way that the expected error decreases.\n",
    "\n",
    "1.4 Provide two examples of metrics used to evaluate the performance of a model and give formula for each one. Give two examples of applications and appropriate metrics for each case.\n",
    "\n",
    "**F1 Score**\n",
    "- F1 is an overall measure of a model's accuracy that combines precision and recall, in that weird way that addition and multiplication just mix two ingredients to make a separate dish altogether.\n",
    "$${F_1}= {(recall^{-1}+precision^{-1})\\over{2}}^{-1}=2\\cdot{precision\\cdot recall\\over{precision+recall}}$$\n",
    "\n",
    "- For the precision and recall for F1 Score: \n",
    "\n",
    "$$Precision={TruePositive \\over {TruePositive + FalsePostiive}}$$\n",
    "$$Recall = {TruePositive \\over {TruePositive+FalseNegative}}$$\n",
    "\n",
    "\n",
    "\n",
    "**R-Squared**\n",
    "- R-squared, also known as the coefficient of determination, is the statistical measurement of the correlation between an investment’s performance and a specific benchmark index. In other words, it shows what degree a stock or portfolio’s performance can be attributed to a benchmark index.\n",
    "$$R^2=1-{MSE(model)\\over{MSE(baseline)}}$$\n",
    "\n",
    "MSE(model) = Mean Squared Error of the predictions against the actual values\n",
    "$$MSE(model)=\\sum_i^N(y_i-\\hat{y})^2$$\n",
    "\n",
    "MSE(baseline) = Mean Squared Error of  mean prediction against the actual values\n",
    "$$MSE(model)=\\sum_i^N(\\bar{y_i}-\\hat{y})^2$$\n",
    "\n",
    "\n",
    "\n",
    "**Example Cases:**\n",
    "1. Evaluation of named entity recognition and word segmentation: F1 Score\n",
    "2. Representing how a funds movements correlates with a benchmark index: R-Squred\"\n",
    "\n",
    "1.5 Why are benchmarks useful in machine learning and give two examples.\n",
    "**Why useful**: \n",
    "    1. Benchmark is standard against which you compare the solutions, to get a feel if the solutions are better or worse.\n",
    "    2. When the benchmarks are “representative,” they allow engineering effort to be focused on a small but high-value and widely used set of targets. In the best cases, benchmarks initiate a virtuous circle, propelling a cycle of optimization and improved value for all members of a community\n",
    "    \n",
    "**Examples**:\n",
    "- For newcomers, benchmarks provide a summary that helps them orient in a maze of new terms and data. \n",
    "- For sophisticates, benchmarks provide an easily portable and quick-to-collect baseline, where specific measurements will give more relevant data, and disagreement between the benchmark and the specific measurement suggests that more investigation is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Machine Learning (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 What is machine learning? Discuss its evolution over time and why is it popular?\n",
    "\n",
    "**What is Machine Learning**\n",
    "\n",
    "Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop a conventional algorithm for effectively performing the task.\n",
    "\n",
    "**Evolution overt time**\n",
    "\n",
    "| Time                                   | Name      | Description |\n",
    "|----------------------------------------|-----------|-------------|\n",
    "| 1950| 4.847677  | 2.935527    |\n",
    "| 1952    | 89.292969 | 93.042404   |\n",
    "|1957||||\n",
    "|1990||||\n",
    "|2010||||\n",
    "|2014||||\n",
    "\n",
    "2.2 Give three examples of machine learning techniques that can be viewed as either supervised or unsupervised approaches.\n",
    "\n",
    "1. Decision Tree (Supervised)\n",
    "2. Linear Regression (Supervised)\n",
    "3. K-means (Unsupervised)\n",
    "\n",
    "2.3 What is the difference between classification and regression?\n",
    "\n",
    "- The main difference between them is that the output variable in regression is numerical (or continuous) while that for classification is categorical (or discrete)\n",
    "\n",
    "\n",
    "2.4 What is the difference between supervised learning and unsupervised learning?\n",
    "\n",
    "- Supervised: All data is labeled and the algorithms learn to predict the output from the input data. \n",
    "- Unsupervised: All data is unlabeled and the algorithms learn to inherent structure from the input data.\n",
    "\n",
    "2.5 Give examples of successful applications of machine learning and explain what technique is appropriate and what type of learning is involved?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Diabetes data (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. Load the diabetes data into MATLAB. Produce a correlation matrix of the explanatory variables. Make a heat-map of the matrix (using imagesc and colorbar) and describe the relationships between the variables.\n",
    "\n",
    "3.2. What is collinearity? What effect does collinearity amongst predictor variables have on their estimated coefficient value?\n",
    "\n",
    "3.3. Create a multivariate model using all ten variables and a constant. In the rest of this assignment this model will be referred to as model1. What are the Mean Squared Error and the adjusted $R^2$ for model1? Are all variables significant? Could this be a problem of collinearity?\n",
    "\n",
    "3.4. What is the difference between forward selection and backward selection?\n",
    "\n",
    "3.5. How does the approach stepwise work in the sense of selecting variables? Use the function stepwise to interactively compose a model using forward selection. Which variables are selected? How does this function work? What is the MSE and R 2 value for this new model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
